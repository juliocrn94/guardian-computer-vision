{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from PIL import Image\n",
    "from statistics import mean\n",
    "import math  \n",
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_people(array):\n",
    "    if isinstance(array, (np.ndarray, np.generic) ) == True:\n",
    "        num_p = array.shape[0]\n",
    "        print(\"# of People in Frame: {}\".format(num_p))\n",
    "        return num_p\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dist_x(array, el_array):\n",
    "    dist_l = []\n",
    "    if isinstance(array, (np.ndarray, np.generic) ) == True:\n",
    "        for i in array:\n",
    "            h1 = abs(i[1]-i[3])\n",
    "            h2 = abs(el_array[1]-el_array[3])\n",
    "            h_ref = max(h1,h2)\n",
    "            \n",
    "            dH1 = i[0]-el_array[0]\n",
    "            dH2 = i[2]-el_array[2]\n",
    "            dH_av = abs(mean([dH1,dH2]))\n",
    "            dH_av = dH_av/(2*h_ref)\n",
    "            \n",
    "            #print(\"h_ref: \",h_ref)\n",
    "            #print(\"dH_av: \",dH_av)\n",
    "            if dH_av > 0:\n",
    "                dist_l.append(dH_av)\n",
    "\n",
    "        if len(dist_l)>0:\n",
    "            #print(dist_l)\n",
    "            return min(dist_l)\n",
    "        else:\n",
    "            return 3\n",
    "    else:\n",
    "        return 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the HOG descriptor/person detector\n",
    "body_det = cv2.HOGDescriptor()\n",
    "body_det.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "face_det = cv2.CascadeClassifier(os.path.join('./models/haarcascade_frontalface_default.xml'))\n",
    "\n",
    "cv2.startWindowThread()\n",
    "\n",
    "# open webcam video stream\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# the output will be written to output.avi\n",
    "out = cv2.VideoWriter(\n",
    "    'output.avi',\n",
    "    cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "    15.,\n",
    "    (640,480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_d = {0:\"No_Mask\",1:\"Mask\"}\n",
    "color_d = {0: (0,0,255), 1: (255,0,0)}\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # resizing for faster detection\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    # flipping image to mirror\n",
    "    frame =cv2.flip(frame,1,1) \n",
    "    \n",
    "    # using a greyscale picture, also for faster detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # detect people in the image\n",
    "    # returns the bounding boxes for the detected people\n",
    "    # TRY WITH GRAY AND FRAME\n",
    "    body_boxes, weights = body_det.detectMultiScale(gray, winStride=(8,8) )\n",
    "    body_boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in body_boxes])\n",
    "    \n",
    "    # detect faces in the image\n",
    "    # returns the bounding boxes for the detected faces\n",
    "    face_boxes = face_det.detectMultiScale(gray)\n",
    "    face_boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in face_boxes])\n",
    "    \n",
    "    # apply non-maxima suppression to the bounding boxes using overlap threshold to try to maintain overlapping\n",
    "    # boxes that are still identificable\n",
    "    body_pick = non_max_suppression(body_boxes, probs=None, overlapThresh=0.5)\n",
    "    face_pick = non_max_suppression(face_boxes, probs=None, overlapThresh=0.5)\n",
    "    \n",
    "    # Testing Results\n",
    "    #print(\"body_pick: \",body_pick)\n",
    "    #print(\"type: \",type(body_pick))\n",
    "    #print(\"dimentions: \", body_pick.shape)\n",
    "    \n",
    "    # Checking number of people in frame\n",
    "    #num_p = num_of_people(face_pick)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for element in body_pick:\n",
    "        (xA, yA, xB, yB) = element\n",
    "        min_dist = calc_dist_x(body_pick, element)\n",
    "        print(\"min_dist: \",min_dist)\n",
    "        if (min_dist > 0) & (min_dist < .2):\n",
    "            color = 0\n",
    "        else:\n",
    "            color = 1\n",
    "        \n",
    "        # display the detected boxes in the colour picture\n",
    "        cv2.rectangle(frame, (xA, yA), (xB, yB), color_d[color], 2)\n",
    "        cv2.putText(frame, \"human\", (xA, yA-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),2)\n",
    "        \n",
    "        #print(\"points: {},{},{},{}\".format(xA, yA, xB, yB))\n",
    "        \n",
    "    for element in face_pick:\n",
    "        (xA, yA, xB, yB) = element\n",
    "        \n",
    "        # Saving FACE IMAGE to a VAR\n",
    "        face_img = gray[yA:yB, xA:xB]\n",
    "        resized=cv2.resize(face_img,(100,100))\n",
    "        cv2.imwrite(\"face.jpg\", resized)\n",
    "        \n",
    "        # display the detected boxes in the colour picture\n",
    "        cv2.rectangle(frame, (xA, yA), (xB, yB), (255,255,255), 2)\n",
    "        cv2.putText(frame, \"face\", (xA, yA-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Write the output video \n",
    "    out.write(frame.astype('uint8'))\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "# and release the output\n",
    "out.release()\n",
    "# finally, close the window\n",
    "for i in range(1,10):\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "# and release the output\n",
    "# out.release()\n",
    "# finally, close the window\n",
    "for i in range(1,10):\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codigo Alberto para mejor lectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "xVectorSize=100\n",
    "yVectorSize=100\n",
    "def getImageVector(img):\n",
    "    #img = Image.open(img)\n",
    "    img = img.resize( (xVectorSize, yVectorSize) )\n",
    "    img = img.convert('L')\n",
    "    return imgToVector(img) \n",
    "#Funcion para vectorizar imagenes y asignales clasificaciÃ³n\n",
    "def imgToVector(img,x=xVectorSize,y=yVectorSize,classification=1):\n",
    "    vector=[]\n",
    "    vector.append(classification)\n",
    "    for j in range(y):\n",
    "        for i in range(x):\n",
    "            vector.append(img.getpixel((i,j)))\n",
    "    return vector\n",
    "def reconstructor(vector,x=xVectorSize,y=yVectorSize):\n",
    "    reb=Image.new('L',(x,y))\n",
    "    for j in range(y):\n",
    "        for i in range(x):\n",
    "            reb.putpixel((i,j),vector[i+j*x]) \n",
    "    return reb\n",
    "def rescale_frame(frame, percent=75):\n",
    "    width = int(frame.shape[1] * percent/ 100)\n",
    "    height = int(frame.shape[0] * percent/ 100)\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(frame, dim, interpolation =cv2.INTER_AREA)\n",
    "def faceslocation(imgpath,foi='file'):\n",
    "    if foi=='file':\n",
    "        original_image = cv2.imread(imgpath)\n",
    "    elif foi==\"img\":\n",
    "        original_image = imgpath\n",
    "    \n",
    "    \n",
    "    grayscale_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "    detected_faces = face_cascade.detectMultiScale(grayscale_image)\n",
    "    return detected_faces\n",
    "def getfaces(imgpath, foi='file'):\n",
    "    \n",
    "    if foi == 'file':\n",
    "        source = Image.open(imgpath)\n",
    "        source = source.convert('L')\n",
    "        detected_faces=faceslocation(imgpath)\n",
    "    elif foi == 'img':\n",
    "        source = cv2.cvtColor(imgpath, cv2.COLOR_BGR2GRAY)\n",
    "        detected_faces=faceslocation(imgpath,foi=\"img\")\n",
    "        \n",
    "    faces=[]\n",
    "    \n",
    "    for i in detected_faces:\n",
    "        tlbr=list(i)\n",
    "        \n",
    "        x=int(tlbr[2])\n",
    "        y=int(tlbr[3])\n",
    "        x_offset=int(tlbr[0])\n",
    "        y_offset=int(tlbr[1])\n",
    "        \n",
    "        if foi == 'file':\n",
    "            face=Image.new('L',(x,y))\n",
    "            for j in range(y):\n",
    "                for i in range(x):\n",
    "                    pixel=source.getpixel((i+x_offset,j+y_offset))\n",
    "                    face.putpixel((i,j),pixel) \n",
    "            faces.append(face)\n",
    "        elif foi == 'img':\n",
    "            face=np.array()\n",
    "            for j in range(y):\n",
    "                for i in range(x):\n",
    "                    pixel=source[i+x_offset,j+y_offset]\n",
    "                    face.putpixel((i,j),pixel) \n",
    "            faces.append(face)\n",
    "    \n",
    "    mask=[] \n",
    "    for face in faces:\n",
    "        X=pd.DataFrame(getImageVector(face)).T\n",
    "        X=X.drop(0,axis=1)\n",
    "        pred=xgbc.predict(X)\n",
    "        mask.append(pred)\n",
    "           \n",
    "    return faces,mask\n",
    "def textInImage(img,text='Prueba Texto'):\n",
    "    font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (50,50)\n",
    "    fontScale              = 1\n",
    "    fontColor              = (255,255,255)\n",
    "    lineType               = 2\n",
    "    cv2.putText(img,text, \n",
    "        bottomLeftCornerOfText, \n",
    "        font, \n",
    "        fontScale,\n",
    "        fontColor,\n",
    "        lineType)\n",
    "    \n",
    "def idSquare(imgpath,fl,pred,foi='file'):\n",
    "    if foi == 'file':\n",
    "        img = cv2.imread(imgpath)\n",
    "    elif foi == 'img':\n",
    "        img=imgpath\n",
    "        \n",
    "    for i in range(len(fl)):\n",
    "        \n",
    "        column=fl[i][0]\n",
    "        row=fl[i][1]\n",
    "        width=fl[i][2]\n",
    "        height=fl[i][3]\n",
    "        \n",
    "        if pred[i][0]== 0:\n",
    "            color=(0,0,255)\n",
    "        else:\n",
    "            color =(0,255,0)\n",
    "        \n",
    "        cv2.rectangle(\n",
    "            img,\n",
    "            (column, row),\n",
    "            (column + width, row + height),\n",
    "            color,\n",
    "            2)\n",
    "    \n",
    "    return img\n",
    "def maskdetector(imgpath,foi='file'):\n",
    "    if foi == 'file':\n",
    "        original_image = cv2.imread(imgpath)\n",
    "        detected_faces=faceslocation(imgpath)\n",
    "        faces,mask=getfaces(imgpath)\n",
    "        img=idSquare(imgpath,detected_faces,mask)\n",
    "    elif foi == 'img':\n",
    "        detected_faces=faceslocation(imgpath,foi='img')\n",
    "        faces,mask=getfaces(imgpath,foi='img')\n",
    "        img=idSquare(imgpath,detected_faces,mask, foi='img')\n",
    "        \n",
    "    return img\n",
    "2:27\n",
    "El siguiente bloque es el que carga el pickle\n",
    "2:27\n",
    "xgbc = []\n",
    "with (open(\"xgbc100x100\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            xgbc.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break\n",
    "xgbc=xgbc[0]\n",
    "2:27\n",
    "y el Ãºltimo es el detector\n",
    "2:28\n",
    "cam = cv2.VideoCapture(0)\n",
    "cv2.startWindowThread()\n",
    "cv2.namedWindow(\"test\")\n",
    "stop=False\n",
    "while stop==False:\n",
    "    ret, frame = cam.read()\n",
    "    imgpath='current_img.png'\n",
    "    cv2.imwrite(imgpath, frame)\n",
    "    \n",
    "    #clear_output(wait=True)\n",
    "    img=maskdetector(imgpath)\n",
    "    #img=maskdetector(frame,'img')\n",
    "    try:\n",
    "        frame50 = rescale_frame(img,percent=50)\n",
    "        cv2.imshow(\"test\", frame50)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    \n",
    "     \n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27: # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        stop=True\n",
    "    \n",
    "cam.release()\n",
    "cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
